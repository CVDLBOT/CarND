{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imread as imread\n",
    "from scipy.misc import imsave as imsave\n",
    "from scipy.misc import imresize as imresize\n",
    "from IPython.display import HTML\n",
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load chessboard images for camera callibration\n",
    "\n",
    "folder = 'camera_cal/'\n",
    "image_files = os.listdir(folder)\n",
    "chessboard_images = []\n",
    "\n",
    "for i in range(len(image_files)):\n",
    "    file_name  = os.path.join(folder, ('calibration' + str(i+1) + '.jpg'))\n",
    "    image_file = imread(file_name, False, 'RGB')\n",
    "    image_file = imresize(image_file, (720, 1280), interp='bilinear')  \n",
    "    chessboard_images.append(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the camera calibration matrix and distortion coefficients \n",
    "# given a set of chessboard images\n",
    "\n",
    "def compute_cal_dist(img):\n",
    "    # Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((6*8,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:8, 0:6].T.reshape(-1,2)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (8,6), None)\n",
    "    \n",
    "    objpoints = objp\n",
    "    imgpoints = corners\n",
    "    \n",
    "    return ret, objpoints, imgpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "for i in range(20):\n",
    "    img = chessboard_images[i]\n",
    "    ret, objp, imp = compute_cal_dist(img)\n",
    "    \n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do camera calibration given object points and image points\n",
    "img = cv2.imread('test_image.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# Do camera calibration given object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calibrate_image(image, mtx, dist):\n",
    "    '''\n",
    "    Applies distortion correction\n",
    "    '''\n",
    "    \n",
    "    # Apply distortion correction to raw images.    \n",
    "    undst = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    \n",
    "    return undst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    '''\n",
    "    To create an edge image\n",
    "    '''\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    \n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "    \n",
    "    # Return the binary image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    '''\n",
    "    To create a gradient image\n",
    "    '''\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color(img, thresh=(0, 255)):\n",
    "    '''\n",
    "    To create a color map image\n",
    "    '''\n",
    "    # Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    # Select the S-channel\n",
    "    S = hls[:,:,2]\n",
    "    \n",
    "    # Take the HLS color space, apply a threshold, and create a binary image result\n",
    "    binary = np.zeros_like(S)\n",
    "    binary[(S > thresh[0]) & (S <= thresh[1])] = 1\n",
    "    \n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    '''\n",
    "    Applies an image mask.\n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    '''\n",
    "    # Defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    # Defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    # Filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    # Returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    \n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corners_unwarp(img, vx1, vx2, vy1, vy2):\n",
    "    '''\n",
    "    Prespective Transform\n",
    "    '''\n",
    "    # Input should be the calibrated Image\n",
    "    undist = img\n",
    "    \n",
    "    # Grab the image shape\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "    # For source points:\n",
    "    src = np.float32([vx1, vx2, vy1, vy2])\n",
    "    \n",
    "    # For destination points:\n",
    "    dst = np.float32([vx1, [vx1[0], 0], [vy2[0], 0], vy2])\n",
    "    \n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    # Compute the inverse perspective transform:\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(undist, M, img_size)\n",
    "    \n",
    "    # Return the resulting image and matrix\n",
    "    return warped, M, Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_map_norm(img):\n",
    "    '''\n",
    "    To normalize the binary image map\n",
    "    '''\n",
    "    # Find the min value in the array\n",
    "    img = np.array(img)\n",
    "    min_value = np.min(img)\n",
    "    \n",
    "    # Loop through each element of the image to replace non-zero elements to 255\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            if img[i][j] >= min_value and img[i][j]!= 0:\n",
    "                img[i][j] = 255.0\n",
    "    \n",
    "    img = img/255.0\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def curvature(top_down, left_lane_inds, right_lane_inds, left_fit, right_fit):\n",
    "    '''\n",
    "    Find the lane curvature\n",
    "    '''\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero  = top_down.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    lefty  = nonzeroy[left_lane_inds] \n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    y_eval1 = np.max(lefty)\n",
    "    y_eval2 = np.max(righty)\n",
    "\n",
    "    left_curverad = ((1 + (2*left_fit[0]*y_eval1 + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*y_eval2  + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    \n",
    "    return left_curverad, right_curverad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def first_lane(image, vertices):\n",
    "    '''\n",
    "    To find the lane in the first frame of video sequence.\n",
    "    ''' \n",
    "    # Apply binary map to the next images.\n",
    "    b_map = mag_thresh(image, sobel_kernel=3, mag_thresh=(40, 150))\n",
    "\n",
    "    # Gradient Orientation\n",
    "    grad  = grad_threshold(image, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "\n",
    "    # Color\n",
    "    color_map = color(image, thresh=(90, 255))\n",
    "    \n",
    "    # Combine\n",
    "    combined = np.zeros_like(grad)\n",
    "    combined[((b_map == 1)) | ((color_map == 1) & (grad == 1))] = 1\n",
    "    \n",
    "    masked_edge_image = region_of_interest(combined, vertices)\n",
    "    masked_image = region_of_interest(image, vertices)\n",
    "    \n",
    "    top_down, M, Minv = corners_unwarp(masked_edge_image, vertices[0,0,:], vertices[0,1,:], vertices[0,2,:], vertices[0,3,:]) \n",
    "    top_down = binary_map_norm(top_down)\n",
    "    \n",
    "    # Compute the histogram\n",
    "    histogram = np.sum(top_down[top_down.shape[0]/2:,:], axis=0)\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint    = np.int(histogram.shape[0]/2)\n",
    "    leftx_base  = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    \n",
    "    # Set height of windows\n",
    "    window_height = np.int(top_down.shape[0]/nwindows)\n",
    "    \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero  = top_down.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current  = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    \n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    \n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = top_down.shape[0] - (window+1)*window_height\n",
    "        win_y_high = top_down.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "\n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds  = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx  = nonzerox[left_lane_inds]\n",
    "    lefty  = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Find the curve:\n",
    "    left_curverad, right_curverad = curvature(top_down, left_lane_inds, right_lane_inds, left_fit, right_fit)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, top_down.shape[0]-1, top_down.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Create an image to draw the lines on\n",
    "    font       = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    warp_zero  = np.zeros_like(masked_edge_image).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left  = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts       = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    cv2.putText(image,'Radius of Curvature: '  + str(left_curverad) + 'm', (400,100), font, 1,(0,255,0),2,cv2.LINE_AA)\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(image, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    return result, left_fit, right_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def second_to_end_lane(image, vertices, left_fit, right_fit):\n",
    "    '''\n",
    "    To find the lane from second frame to end\n",
    "    '''\n",
    "\n",
    "    # Apply binary map to the next images.\n",
    "    b_map = mag_thresh(image, sobel_kernel=3, mag_thresh=(40, 150))\n",
    "\n",
    "    # Gradient Orientation\n",
    "    grad  = grad_threshold(image, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "\n",
    "    # Color\n",
    "    color_map = color(image, thresh=(90, 255))\n",
    "    \n",
    "    # Combine\n",
    "    combined = np.zeros_like(grad)\n",
    "    combined[((b_map == 1)) | ((color_map == 1) & (grad == 1))] = 1\n",
    "\n",
    "    masked_edge_image = region_of_interest(combined, vertices)\n",
    "    masked_image = region_of_interest(image, vertices)\n",
    "    \n",
    "    top_down, M, Minv = corners_unwarp(masked_edge_image, vertices[0,0,:], vertices[0,1,:], vertices[0,2,:], vertices[0,3,:]) \n",
    "    top_down = binary_map_norm(top_down)\n",
    "\n",
    "    nonzero  = top_down.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin   = 100\n",
    "    left_lane_inds  = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx  = nonzerox[left_lane_inds]\n",
    "    lefty  = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit  = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, top_down.shape[0]-1, top_down.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1  = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2  = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "    left_line_pts      = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "    right_line_pts     = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Find the curve:\n",
    "    left_curverad, right_curverad = curvature(top_down, left_lane_inds, right_lane_inds, left_fit, right_fit)\n",
    "\n",
    "    # Create an image to draw the lines on\n",
    "    font       = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    warp_zero  = np.zeros_like(masked_edge_image).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left  = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts       = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    cv2.putText(image,'Radius of Curvature: '  + str(left_curverad) + 'm', (400,100), font, 1,(0,255,0),2,cv2.LINE_AA)\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(image, 1, newwarp, 0.3, 0)\n",
    "\n",
    "    return result, left_fit, right_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Video and Extract frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Sequence shape:  (1260, 720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load Video\n",
    "clip = VideoFileClip(\"project_video.mp4\")\n",
    "\n",
    "# Get the frames from the video\n",
    "frames = []\n",
    "for x in clip.iter_frames():\n",
    "    frames.append(x)\n",
    "\n",
    "# Convert the sequence to numpy array\n",
    "frames = np.array(frames)\n",
    "print('Frame Sequence shape: ', frames.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lane Finding Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting:  > > > > > > > > > > > > > end "
     ]
    }
   ],
   "source": [
    "# Define Vertices:\n",
    "vertices = np.array([[(240,720),(580, 440), (700, 440), (1200,720)]], dtype=np.int32)\n",
    "\n",
    "# To save\n",
    "lane_map = []\n",
    "\n",
    "print('Starting: ', end=\" \")\n",
    "\n",
    "# Get first frame\n",
    "frame = frames[0, :, :, :]\n",
    "\n",
    "# Correct for distortion\n",
    "undist_frame = calibrate_image(frame, mtx, dist)\n",
    "\n",
    "# Find the lane\n",
    "result, left_fit, right_fit = first_lane(undist_frame, vertices)\n",
    "\n",
    "# Append the final result\n",
    "lane_map.append(result)\n",
    "\n",
    "print ('>', end= \" \")\n",
    "\n",
    "# From Second frame to the end\n",
    "for i in range(1, frames.shape[0]):\n",
    "    # Get frame\n",
    "    frame = frames[i, :, :, :]\n",
    "    \n",
    "    # Correct for distortion\n",
    "    undist_frame = calibrate_image(frame, mtx, dist)\n",
    "    \n",
    "    # Find the lane\n",
    "    result, left_fit, right_fit = second_to_end_lane(undist_frame, vertices, left_fit, right_fit)\n",
    "    \n",
    "    # Append the final result\n",
    "    lane_map.append(result)\n",
    "    \n",
    "    # Progress Bar, every 100 frames.\n",
    "    if i%100 == 0:\n",
    "        print ('>', end= \" \")\n",
    "\n",
    "print ('end', end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the output to output_images directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving: > > > > > > > > > > > > > end "
     ]
    }
   ],
   "source": [
    "# Save the output image\n",
    "print('Saving: >', end=\" \")\n",
    "\n",
    "for j in range(len(lane_map)):\n",
    "    # Get the output image\n",
    "    image = lane_map[j]\n",
    "    \n",
    "    # Filename to save\n",
    "    name  = 'output_images/'+(str(j)+'.jpg')\n",
    "    \n",
    "    # Save the image to directory\n",
    "    imsave(name, image)\n",
    "    \n",
    "    # Increment counter\n",
    "    j += 1\n",
    "    \n",
    "    # Progress Bar, every 100 frames\n",
    "    \n",
    "    if j%100 == 0:\n",
    "        print ('>', end= \" \")\n",
    "\n",
    "print ('end', end=\" \") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Output Frames to Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the codec and create VideoWriter object\n",
    "\n",
    "import skvideo.io\n",
    "\n",
    "writer = skvideo.io.FFmpegWriter(\"output.mp4\", outputdict={'-vcodec': 'libx264', '-b': '30000000'}) \n",
    "\n",
    "for i in range(1260):\n",
    "    filename = 'output_images/' + str(i) + '.jpg'\n",
    "    read = imread(filename, False, 'RGB')\n",
    "    read = np.array(read)\n",
    "    \n",
    "    # Write to video\n",
    "    writer.writeFrame(read)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"320\" height=\"200\" controls>\n",
       "  <source src=\"output.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"320\" height=\"200\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(\"output.mp4\"))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
